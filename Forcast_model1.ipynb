{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Prepare the dataset.\n",
        "\n",
        "#Unzip the file ('Walmart_Store_sales.zip')\n",
        "with zipfile.ZipFile('Walmart_Store_sales.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('unzipped_dataset')\n",
        "\n",
        "#Load the CSV file (replace 'Walmart.csv' with your actual file name)\n",
        "file_path = 'unzipped_dataset/Walmart.csv'  # Update with the correct file name\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Print the column names to verify\n",
        "print(\"Columns in the dataset:\", data.columns)\n",
        "\n",
        "# Convert 'Date' to datetime format with dayfirst=True to match 'dd-mm-yyyy' format\n",
        "data['Date'] = pd.to_datetime(data['Date'], dayfirst=True)\n",
        "\n",
        "# Convert the 'Date' column to a numerical format (Unix timestamp)\n",
        "data['Date'] = data['Date'].astype(int) / 10**9  # Convert to seconds since epoch\n",
        "\n",
        "# Preprocess the data\n",
        "data.fillna(method='ffill', inplace=True)\n",
        "feature_columns = ['Date', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
        "data[feature_columns] = StandardScaler().fit_transform(data[feature_columns])\n",
        "sales_scaler = StandardScaler()\n",
        "data['Weekly_Sales'] = sales_scaler.fit_transform(data[['Weekly_Sales']])\n",
        "data = pd.get_dummies(data, columns=['Store', 'Holiday_Flag'])\n",
        "\n",
        "# Split the data\n",
        "X = data.drop(columns=['Weekly_Sales'])\n",
        "y = data['Weekly_Sales']\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to numpy arrays and ensure correct data types\n",
        "X_train_np = X_train.values.astype(np.float32)\n",
        "X_val_np = X_val.values.astype(np.float32)\n",
        "y_train_np = y_train.values.astype(np.float32)\n",
        "y_val_np = y_val.values.astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "# LSTM and training\n",
        "\n",
        "# Reshape the data to 3D for LSTM\n",
        "X_train_np = np.reshape(X_train_np, (X_train_np.shape[0], 1, X_train_np.shape[1]))\n",
        "X_val_np = np.reshape(X_val_np, (X_val_np.shape[0], 1, X_val_np.shape[1]))\n",
        "\n",
        "# Check the shapes of the arrays\n",
        "print(\"Reshaped training data shape:\", X_train_np.shape)\n",
        "print(\"Reshaped validation data shape:\", X_val_np.shape)\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Add an LSTM layer\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train_np.shape[1], X_train_np.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Add the output layer\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_np, y_train_np, epochs=50, batch_size=32, validation_data=(X_val_np, y_val_np), shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "# Model evaluation, predictions and plotting.\n",
        "\n",
        "# Evaluate the model\n",
        "val_loss = model.evaluate(X_val_np, y_val_np)\n",
        "print(\"Validation Loss:\", val_loss)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_val_np)\n",
        "\n",
        "# Inverse transform the predictions and actual values if needed\n",
        "predictions = sales_scaler.inverse_transform(predictions)\n",
        "y_val_actual = sales_scaler.inverse_transform(y_val_np.reshape(-1, 1))\n",
        "\n",
        "# Display the first few predictions\n",
        "print(\"Predicted values:\", predictions[:5])\n",
        "print(\"Actual values:\", y_val_actual[:5])\n",
        "\n",
        "# Visualize the Results\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.plot(y_val_actual, color='blue', label='Actual Weekly Sales')\n"
      ],
      "metadata": {
        "id": "ASMC5yKZvQwB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}